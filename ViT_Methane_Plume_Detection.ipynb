{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V41iVUW4UJUd",
        "outputId": "94887e8b-380b-46c6-9e8a-71a9ca3d443d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qYewlVNpUhhf"
      },
      "outputs": [],
      "source": [
        "import google\n",
        "import shutil\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from einops import rearrange\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvwDpJt3Veer",
        "outputId": "47ee0324-6a0c-4253-f2df-3b0327a66c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "google.colab.drive.mount('/content/drive/')\n",
        "\n",
        "shutil.unpack_archive('/content/drive/MyDrive/ViT_Methane_Plume_Detection/Dataset.zip', '/content/drive/MyDrive/ViT_Methane_Plume_Detection')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/ViT_Methane_Plume_Detection')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512,512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "#train_data = datasets.CIFAR10(root='/.data',train=True, download=True, transform=transform)\n",
        "#test_data = datasets.CIFAR10(root='/.data', train=False, download=True, transform=transform)\n",
        "train_data = datasets.ImageFolder(root='Dataset/train', transform=transform)\n",
        "val_data = datasets.ImageFolder(root='Dataset/val', transform=transform)\n",
        "test_data = datasets.ImageFolder(root='Dataset/test', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BGccpKdJWBQW"
      },
      "outputs": [],
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "      def __init__(self, in_channels=3, patch_size=64, emb_size=64, img_size=32):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Conv2d(in_channels, emb_size,\n",
        "                                    kernel_size=patch_size, stride=patch_size)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, (img_size//patch_size)**2+1, emb_size))\n",
        "\n",
        "      def forward(self,x):\n",
        "\n",
        "        B = x.shape[0]\n",
        "        x = self.projection(x)\n",
        "        x = x.flatten(2).transpose(1,2)\n",
        "        cls_token = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_token, x), dim=1)\n",
        "        x = x + self.pos_embedding\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rqGz31BCX-1j"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, emb_size=64, num_heads=4, mlp_ratio=4, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.norm1 =nn.LayerNorm(emb_size)\n",
        "    self.atten = nn.MultiheadAttention(emb_size, num_heads, dropout, batch_first=True)\n",
        "    self.norm2 =nn.LayerNorm(emb_size)\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(emb_size, int(emb_size * mlp_ratio)),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(int(emb_size * mlp_ratio), emb_size),\n",
        "        nn.Dropout(dropout)\n",
        "\n",
        "    )\n",
        "  def forward(self,x):\n",
        "      x = x + self.atten(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
        "      x = x + self.mlp(self.norm2(x))\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wj0pnI8wbNEO"
      },
      "outputs": [],
      "source": [
        "class ViT(nn.Module):\n",
        "  def __init__(self, img_size=32, patch_size=64, emb_size=64, depth=4, num_heads=4, num_classes=2):\n",
        "    super().__init__()\n",
        "    self.patch_embed= PatchEmbedding(3, patch_size, emb_size, img_size)\n",
        "    self.encoder = nn.Sequential(*[TransformerEncoder(emb_size, num_heads) for _ in range(depth)])\n",
        "    self.norm = nn.LayerNorm(emb_size)\n",
        "    self.fc = nn.Linear(emb_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.patch_embed(x)\n",
        "    x = self.encoder(x)\n",
        "    x = self.norm(x)\n",
        "    cls_token = x[:,0]\n",
        "\n",
        "    return self.fc(cls_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phdM9gAKeDkT",
        "outputId": "7d42eeab-d275-476f-a67d-38c3afd9856f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 94.0898, Validation Loss: 41.7403\n",
            "Train Accuracy: 30.9524, Validation Accuracy: 33.2500\n",
            "Epoch 2 | Train Loss: 44.0248, Validation Loss: 46.0658\n",
            "Train Accuracy: 30.1429, Validation Accuracy: 33.2500\n",
            "Epoch 3 | Train Loss: 45.4546, Validation Loss: 41.6461\n",
            "Train Accuracy: 30.1429, Validation Accuracy: 33.2500\n",
            "Epoch 4 | Train Loss: 42.8706, Validation Loss: 42.1870\n",
            "Train Accuracy: 31.2857, Validation Accuracy: 33.2500\n",
            "Epoch 5 | Train Loss: 42.5037, Validation Loss: 42.8423\n",
            "Train Accuracy: 32.4286, Validation Accuracy: 33.2500\n",
            "Epoch 6 | Train Loss: 42.9068, Validation Loss: 41.7971\n",
            "Train Accuracy: 32.2857, Validation Accuracy: 33.2500\n",
            "Epoch 7 | Train Loss: 42.3623, Validation Loss: 41.7248\n",
            "Train Accuracy: 32.1429, Validation Accuracy: 33.2500\n",
            "Epoch 8 | Train Loss: 42.4200, Validation Loss: 41.6651\n",
            "Train Accuracy: 32.7619, Validation Accuracy: 33.2500\n",
            "Epoch 9 | Train Loss: 42.3361, Validation Loss: 41.9061\n",
            "Train Accuracy: 33.0952, Validation Accuracy: 33.7500\n",
            "Epoch 10 | Train Loss: 42.5524, Validation Loss: 41.6442\n",
            "Train Accuracy: 32.1429, Validation Accuracy: 33.2500\n",
            "Epoch 11 | Train Loss: 42.5777, Validation Loss: 41.6644\n",
            "Train Accuracy: 31.5714, Validation Accuracy: 33.2500\n",
            "Epoch 12 | Train Loss: 42.4452, Validation Loss: 42.0725\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 13 | Train Loss: 42.4749, Validation Loss: 42.2330\n",
            "Train Accuracy: 33.1905, Validation Accuracy: 33.2500\n",
            "Epoch 14 | Train Loss: 42.8200, Validation Loss: 41.7949\n",
            "Train Accuracy: 32.7619, Validation Accuracy: 33.2500\n",
            "Epoch 15 | Train Loss: 42.3922, Validation Loss: 41.7944\n",
            "Train Accuracy: 31.8571, Validation Accuracy: 33.2500\n",
            "Epoch 16 | Train Loss: 42.4117, Validation Loss: 41.6607\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 17 | Train Loss: 42.5432, Validation Loss: 41.7181\n",
            "Train Accuracy: 31.2857, Validation Accuracy: 33.2500\n",
            "Epoch 18 | Train Loss: 42.2918, Validation Loss: 41.8444\n",
            "Train Accuracy: 33.0476, Validation Accuracy: 33.2500\n",
            "Epoch 19 | Train Loss: 42.4087, Validation Loss: 41.6780\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 20 | Train Loss: 42.3637, Validation Loss: 41.6385\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 21 | Train Loss: 42.7780, Validation Loss: 42.3657\n",
            "Train Accuracy: 30.6667, Validation Accuracy: 33.2500\n",
            "Epoch 22 | Train Loss: 42.6150, Validation Loss: 41.9720\n",
            "Train Accuracy: 32.3810, Validation Accuracy: 33.2500\n",
            "Epoch 23 | Train Loss: 42.3991, Validation Loss: 41.7943\n",
            "Train Accuracy: 33.5238, Validation Accuracy: 33.2500\n",
            "Epoch 24 | Train Loss: 42.4461, Validation Loss: 41.6391\n",
            "Train Accuracy: 31.8571, Validation Accuracy: 33.2500\n",
            "Epoch 25 | Train Loss: 42.3505, Validation Loss: 41.6850\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 26 | Train Loss: 42.3045, Validation Loss: 41.9569\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 27 | Train Loss: 42.3408, Validation Loss: 41.7547\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 28 | Train Loss: 42.4088, Validation Loss: 41.9874\n",
            "Train Accuracy: 33.2857, Validation Accuracy: 33.2500\n",
            "Epoch 29 | Train Loss: 42.3197, Validation Loss: 41.9969\n",
            "Train Accuracy: 33.0000, Validation Accuracy: 33.2500\n",
            "Epoch 30 | Train Loss: 42.4066, Validation Loss: 41.6779\n",
            "Train Accuracy: 33.0476, Validation Accuracy: 33.2500\n",
            "Epoch 31 | Train Loss: 42.3012, Validation Loss: 41.8744\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 32 | Train Loss: 42.4762, Validation Loss: 41.7154\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 33 | Train Loss: 42.4062, Validation Loss: 41.7201\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 34 | Train Loss: 42.9097, Validation Loss: 41.6718\n",
            "Train Accuracy: 29.7143, Validation Accuracy: 33.2500\n",
            "Epoch 35 | Train Loss: 42.3657, Validation Loss: 41.6718\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 36 | Train Loss: 42.8585, Validation Loss: 41.8013\n",
            "Train Accuracy: 31.6667, Validation Accuracy: 33.2500\n",
            "Epoch 37 | Train Loss: 43.0064, Validation Loss: 41.7018\n",
            "Train Accuracy: 31.2857, Validation Accuracy: 33.2500\n",
            "Epoch 38 | Train Loss: 42.4263, Validation Loss: 41.6744\n",
            "Train Accuracy: 32.2857, Validation Accuracy: 33.2500\n",
            "Epoch 39 | Train Loss: 42.7564, Validation Loss: 42.0514\n",
            "Train Accuracy: 31.8571, Validation Accuracy: 27.2500\n",
            "Epoch 40 | Train Loss: 42.2514, Validation Loss: 41.6490\n",
            "Train Accuracy: 33.1429, Validation Accuracy: 33.2500\n",
            "Epoch 41 | Train Loss: 42.3181, Validation Loss: 41.6899\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 42 | Train Loss: 42.3015, Validation Loss: 41.6464\n",
            "Train Accuracy: 33.4762, Validation Accuracy: 33.2500\n",
            "Epoch 43 | Train Loss: 42.5459, Validation Loss: 41.6786\n",
            "Train Accuracy: 32.1429, Validation Accuracy: 33.2500\n",
            "Epoch 44 | Train Loss: 42.6245, Validation Loss: 41.7147\n",
            "Train Accuracy: 31.5714, Validation Accuracy: 33.2500\n",
            "Epoch 45 | Train Loss: 42.8901, Validation Loss: 42.7502\n",
            "Train Accuracy: 31.2857, Validation Accuracy: 27.2500\n",
            "Epoch 46 | Train Loss: 42.4524, Validation Loss: 41.6844\n",
            "Train Accuracy: 33.8095, Validation Accuracy: 33.2500\n",
            "Epoch 47 | Train Loss: 42.9383, Validation Loss: 41.6544\n",
            "Train Accuracy: 31.5714, Validation Accuracy: 33.2500\n",
            "Epoch 48 | Train Loss: 42.8370, Validation Loss: 41.8096\n",
            "Train Accuracy: 31.7143, Validation Accuracy: 33.2500\n",
            "Epoch 49 | Train Loss: 42.8333, Validation Loss: 42.0849\n",
            "Train Accuracy: 31.9524, Validation Accuracy: 27.2500\n",
            "Epoch 50 | Train Loss: 42.4909, Validation Loss: 41.6635\n",
            "Train Accuracy: 32.7619, Validation Accuracy: 33.2500\n",
            "Epoch 51 | Train Loss: 42.8184, Validation Loss: 41.6615\n",
            "Train Accuracy: 30.7143, Validation Accuracy: 33.2500\n",
            "Epoch 52 | Train Loss: 42.4011, Validation Loss: 41.9290\n",
            "Train Accuracy: 33.0000, Validation Accuracy: 33.0000\n",
            "Epoch 53 | Train Loss: 42.4729, Validation Loss: 41.6399\n",
            "Train Accuracy: 30.9524, Validation Accuracy: 33.2500\n",
            "Epoch 54 | Train Loss: 42.4168, Validation Loss: 41.6910\n",
            "Train Accuracy: 33.3810, Validation Accuracy: 33.2500\n",
            "Epoch 55 | Train Loss: 42.5310, Validation Loss: 42.7026\n",
            "Train Accuracy: 32.4762, Validation Accuracy: 27.2500\n",
            "Epoch 56 | Train Loss: 42.5674, Validation Loss: 41.6953\n",
            "Train Accuracy: 31.6667, Validation Accuracy: 33.2500\n",
            "Epoch 57 | Train Loss: 43.2109, Validation Loss: 42.6633\n",
            "Train Accuracy: 31.4762, Validation Accuracy: 27.2500\n",
            "Epoch 58 | Train Loss: 43.2245, Validation Loss: 41.8184\n",
            "Train Accuracy: 31.4286, Validation Accuracy: 33.2500\n",
            "Epoch 59 | Train Loss: 43.0060, Validation Loss: 42.5829\n",
            "Train Accuracy: 32.0952, Validation Accuracy: 27.2500\n",
            "Epoch 60 | Train Loss: 42.7105, Validation Loss: 41.6664\n",
            "Train Accuracy: 30.8095, Validation Accuracy: 33.2500\n",
            "Epoch 61 | Train Loss: 42.5264, Validation Loss: 42.0644\n",
            "Train Accuracy: 33.0476, Validation Accuracy: 33.2500\n",
            "Epoch 62 | Train Loss: 42.6917, Validation Loss: 42.1263\n",
            "Train Accuracy: 32.8095, Validation Accuracy: 27.2500\n",
            "Epoch 63 | Train Loss: 42.4806, Validation Loss: 41.9812\n",
            "Train Accuracy: 32.6667, Validation Accuracy: 27.2500\n",
            "Epoch 64 | Train Loss: 42.5393, Validation Loss: 44.9092\n",
            "Train Accuracy: 32.1429, Validation Accuracy: 27.2500\n",
            "Epoch 65 | Train Loss: 44.2864, Validation Loss: 48.3895\n",
            "Train Accuracy: 30.7619, Validation Accuracy: 27.2500\n",
            "Epoch 66 | Train Loss: 43.4251, Validation Loss: 43.7444\n",
            "Train Accuracy: 32.0952, Validation Accuracy: 27.2500\n",
            "Epoch 67 | Train Loss: 42.6090, Validation Loss: 41.8352\n",
            "Train Accuracy: 32.1429, Validation Accuracy: 33.2500\n",
            "Epoch 68 | Train Loss: 42.9807, Validation Loss: 41.7676\n",
            "Train Accuracy: 32.0000, Validation Accuracy: 33.2500\n",
            "Epoch 69 | Train Loss: 42.4842, Validation Loss: 45.5670\n",
            "Train Accuracy: 32.0000, Validation Accuracy: 33.2500\n",
            "Epoch 70 | Train Loss: 43.6479, Validation Loss: 42.8014\n",
            "Train Accuracy: 31.1429, Validation Accuracy: 27.2500\n",
            "Epoch 71 | Train Loss: 42.9611, Validation Loss: 41.8599\n",
            "Train Accuracy: 30.6667, Validation Accuracy: 33.2500\n",
            "Epoch 72 | Train Loss: 42.5188, Validation Loss: 41.6785\n",
            "Train Accuracy: 32.9048, Validation Accuracy: 33.2500\n",
            "Epoch 73 | Train Loss: 43.4177, Validation Loss: 42.4298\n",
            "Train Accuracy: 30.5238, Validation Accuracy: 33.2500\n",
            "Epoch 74 | Train Loss: 42.8700, Validation Loss: 42.9473\n",
            "Train Accuracy: 30.9048, Validation Accuracy: 33.2500\n",
            "Epoch 75 | Train Loss: 42.8622, Validation Loss: 52.1233\n",
            "Train Accuracy: 33.1905, Validation Accuracy: 33.2500\n",
            "Epoch 76 | Train Loss: 44.4858, Validation Loss: 43.0855\n",
            "Train Accuracy: 30.3333, Validation Accuracy: 33.2500\n",
            "Epoch 77 | Train Loss: 42.6738, Validation Loss: 42.0374\n",
            "Train Accuracy: 33.0000, Validation Accuracy: 27.2500\n",
            "Epoch 78 | Train Loss: 42.3665, Validation Loss: 41.6410\n",
            "Train Accuracy: 33.2857, Validation Accuracy: 33.2500\n",
            "Epoch 79 | Train Loss: 42.3982, Validation Loss: 41.8192\n",
            "Train Accuracy: 33.0476, Validation Accuracy: 33.2500\n",
            "Epoch 80 | Train Loss: 42.3751, Validation Loss: 42.0339\n",
            "Train Accuracy: 33.0000, Validation Accuracy: 27.2500\n",
            "Epoch 81 | Train Loss: 42.4854, Validation Loss: 41.6957\n",
            "Train Accuracy: 31.2857, Validation Accuracy: 33.2500\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = ViT().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(200):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  train_correct = 0\n",
        "  for imgs, labels in train_loader:\n",
        "\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    outputs = model(imgs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item() * imgs.size(0)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    train_correct += (preds == labels).sum().item()\n",
        "\n",
        "  #__VALIDATION_PHASE__\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "  val_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for imgs,labels in val_loader:\n",
        "\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      outputs = model(imgs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item() * imgs.size(0)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      val_correct += (preds == labels).sum().item()\n",
        "\n",
        "  train_acc = train_correct / len(train_loader)\n",
        "  val_acc = val_correct / len(val_loader)\n",
        "  print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
        "  print(f\"Train Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"plume_model_AdamW_Epoch_200_lr_e-1.pth\")"
      ],
      "metadata": {
        "id": "GVzsQF6X1re-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJPuhjsTkmKV"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in test_loader:\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    preds = model(imgs)\n",
        "    _, predicted = preds.max(1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f\"Test Accuracy: {100* correct/total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVVWVI-ynXrD"
      },
      "outputs": [],
      "source": [
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "outputs = model (images.to(device))\n",
        "_, preds = torch.max(outputs, 1)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(images[i].permute(1,2,0)*0.5 + 0.5)\n",
        "  ax.set_title(f\"Pred: {preds[i].item()}\")\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Plume','Plume Free'])\n",
        "disp.plot(plt.cm.blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AyouYAO2GBHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}